-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 46


-- !query 0
CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1
-- !query 0 schema
struct<>
-- !query 0 output



-- !query 1
CREATE TABLE empsalary (
    depname string,
    empno integer,
    salary int,
    enroll_date date
) USING parquet
-- !query 1 schema
struct<>
-- !query 1 output



-- !query 2
INSERT INTO empsalary VALUES ('develop', 10, 5200, cast ('2007-08-01' as date))
-- !query 2 schema
struct<>
-- !query 2 output



-- !query 3
INSERT INTO empsalary VALUES ('sales', 1, 5000, cast ('2006-10-01' as date))
-- !query 3 schema
struct<>
-- !query 3 output



-- !query 4
INSERT INTO empsalary VALUES ('personnel', 5, 3500, cast ('2007-12-10' as date))
-- !query 4 schema
struct<>
-- !query 4 output



-- !query 5
INSERT INTO empsalary VALUES ('sales', 4, 4800, cast ('2007-08-08' as date))
-- !query 5 schema
struct<>
-- !query 5 output



-- !query 6
INSERT INTO empsalary VALUES ('personnel', 2, 3900, cast ('2006-12-23' as date))
-- !query 6 schema
struct<>
-- !query 6 output



-- !query 7
INSERT INTO empsalary VALUES ('develop', 7, 4200, cast ('2008-01-01' as date))
-- !query 7 schema
struct<>
-- !query 7 output



-- !query 8
INSERT INTO empsalary VALUES ('develop', 9, 4500, cast ('2008-01-01' as date))
-- !query 8 schema
struct<>
-- !query 8 output



-- !query 9
INSERT INTO empsalary VALUES ('sales', 3, 4800, cast ('2007-08-01' as date))
-- !query 9 schema
struct<>
-- !query 9 output



-- !query 10
INSERT INTO empsalary VALUES ('develop', 8, 6000, cast ('2006-10-01' as date))
-- !query 10 schema
struct<>
-- !query 10 output



-- !query 11
INSERT INTO empsalary VALUES ('develop', 11, 5200, cast ('2007-08-15' as date))
-- !query 11 schema
struct<>
-- !query 11 output



-- !query 12
create table datetimes (
    id int,
    f_time timestamp,
    f_timetz timestamp,
    f_interval timestamp,
    f_timestamptz timestamp,
    f_timestamp timestamp
) using parquet
-- !query 12 schema
struct<>
-- !query 12 output



-- !query 13
insert into datetimes values (1, cast ('11:00' as timestamp), cast ('11:00 BST' as timestamp), cast ('1 year' as timestamp), cast ('2000-10-19 10:23:54+01' as timestamp), cast('2000-10-19 10:23:54' as timestamp))
-- !query 13 schema
struct<>
-- !query 13 output



-- !query 14
insert into datetimes values (2, cast ('12:00' as timestamp), cast ('12:00 BST' as timestamp), cast ('2 years' as timestamp), cast ('2001-10-19 10:23:54+01' as timestamp), cast ('2001-10-19 10:23:54' as timestamp))
-- !query 14 schema
struct<>
-- !query 14 output



-- !query 15
insert into datetimes values (3, cast ('13:00' as timestamp), cast ('13:00 BST' as timestamp), cast ('3 years' as timestamp), cast ('2001-10-19 10:23:54+01' as timestamp), cast ('2001-10-19 10:23:54' as timestamp))
-- !query 15 schema
struct<>
-- !query 15 output



-- !query 16
insert into datetimes values (4, cast ('14:00' as timestamp), cast ('14:00 BST' as timestamp), cast ('4 years' as timestamp), cast ('2002-10-19 10:23:54+01' as timestamp), cast ('2002-10-19 10:23:54' as timestamp))
-- !query 16 schema
struct<>
-- !query 16 output



-- !query 17
insert into datetimes values (5, cast ('15:00' as timestamp), cast ('15:00 BST' as timestamp), cast ('5 years' as timestamp), cast ('2003-10-19 10:23:54+01' as timestamp), cast ('2003-10-19 10:23:54' as timestamp))
-- !query 17 schema
struct<>
-- !query 17 output



-- !query 18
insert into datetimes values (6, cast ('15:00' as timestamp), cast ('15:00 BST' as timestamp), cast ('5 years' as timestamp), cast ('2004-10-19 10:23:54+01' as timestamp), cast ('2004-10-19 10:23:54' as timestamp))
-- !query 18 schema
struct<>
-- !query 18 output



-- !query 19
insert into datetimes values (7, cast ('17:00' as timestamp), cast ('17:00 BST' as timestamp), cast ('7 years' as timestamp), cast ('2005-10-19 10:23:54+01' as timestamp), cast ('2005-10-19 10:23:54' as timestamp))
-- !query 19 schema
struct<>
-- !query 19 output



-- !query 20
insert into datetimes values (8, cast ('18:00' as timestamp), cast ('18:00 BST' as timestamp), cast ('8 years' as timestamp), cast ('2006-10-19 10:23:54+01' as timestamp), cast ('2006-10-19 10:23:54' as timestamp))
-- !query 20 schema
struct<>
-- !query 20 output



-- !query 21
insert into datetimes values (9, cast ('19:00' as timestamp), cast ('19:00 BST' as timestamp), cast ('9 years' as timestamp), cast ('2007-10-19 10:23:54+01' as timestamp), cast ('2007-10-19 10:23:54' as timestamp))
-- !query 21 schema
struct<>
-- !query 21 output



-- !query 22
insert into datetimes values (10, cast ('20:00' as timestamp), cast ('20:00 BST' as timestamp), cast ('10 years' as timestamp), cast ('2008-10-19 10:23:54+01' as timestamp), cast ('2008-10-19 10:23:54' as timestamp))
-- !query 22 schema
struct<>
-- !query 22 output



-- !query 23
WITH cte (x) AS (
        SELECT * FROM range(1, 36, 2)
)
SELECT x, (sum(x) over w)
FROM cte
WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following)
-- !query 23 schema
struct<x:bigint,sum(x) OVER (ORDER BY x ASC NULLS FIRST ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING):bigint>
-- !query 23 output
1	4
11	33
13	39
15	45
17	51
19	57
21	63
23	69
25	75
27	81
29	87
3	9
31	93
33	99
35	68
5	15
7	21
9	27


-- !query 24
WITH cte (x) AS (
        SELECT * FROM range(1, 36, 2)
)
SELECT x, (sum(x) over w)
FROM cte
WINDOW w AS (ORDER BY x range between 1 preceding and 1 following)
-- !query 24 schema
struct<x:bigint,sum(x) OVER (ORDER BY x ASC NULLS FIRST RANGE BETWEEN CAST((- 1) AS BIGINT) FOLLOWING AND CAST(1 AS BIGINT) FOLLOWING):bigint>
-- !query 24 output
1	1
11	11
13	13
15	15
17	17
19	19
21	21
23	23
25	25
27	27
29	29
3	3
31	31
33	33
35	35
5	5
7	7
9	9


-- !query 25
WITH cte (x) AS (
        select 1 union all select 1 union all select 1 union all
        SELECT * FROM range(5, 50, 2)
)
SELECT x, (sum(x) over w)
FROM cte
WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following)
-- !query 25 schema
struct<x:bigint,sum(x) OVER (ORDER BY x ASC NULLS FIRST ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING):bigint>
-- !query 25 output
1	2
1	3
1	7
11	33
13	39
15	45
17	51
19	57
21	63
23	69
25	75
27	81
29	87
31	93
33	99
35	105
37	111
39	117
41	123
43	129
45	135
47	141
49	96
5	13
7	21
9	27


-- !query 26
WITH cte (x) AS (
        select 1 union all select 1 union all select 1 union all
        SELECT * FROM range(5, 50, 2)
)
SELECT x, (sum(x) over w)
FROM cte
WINDOW w AS (ORDER BY x range between 1 preceding and 1 following)
-- !query 26 schema
struct<x:bigint,sum(x) OVER (ORDER BY x ASC NULLS FIRST RANGE BETWEEN CAST((- 1) AS BIGINT) FOLLOWING AND CAST(1 AS BIGINT) FOLLOWING):bigint>
-- !query 26 output
1	3
1	3
1	3
11	11
13	13
15	15
17	17
19	19
21	21
23	23
25	25
27	27
29	29
31	31
33	33
35	35
37	37
39	39
41	41
43	43
45	45
47	47
49	49
5	5
7	7
9	9


-- !query 27
SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0
-- !query 27 schema
struct<count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):bigint>
-- !query 27 output



-- !query 28
create table t1 (f1 int, f2 int) using parquet
-- !query 28 schema
struct<>
-- !query 28 output



-- !query 29
insert into t1 values (1,1),(1,2),(2,2)
-- !query 29 schema
struct<>
-- !query 29 output



-- !query 30
select f1, sum(f1) over (partition by f1
                         range between 1 preceding and 1 following)
from t1 where f1 = f2
-- !query 30 schema
struct<>
-- !query 30 output
org.apache.spark.sql.AnalysisException
cannot resolve '(PARTITION BY default.t1.`f1` RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.; line 1 pos 24


-- !query 31
select f1, sum(f1) over (partition by f1, f1 order by f2
range between 2 preceding and 1 preceding)
from t1 where f1 = f2
-- !query 31 schema
struct<f1:int,sum(f1) OVER (PARTITION BY f1, f1 ORDER BY f2 ASC NULLS FIRST RANGE BETWEEN 2 PRECEDING AND 1 PRECEDING):bigint>
-- !query 31 output
1	NULL
2	NULL


-- !query 32
select f1, sum(f1) over (partition by f1, f2 order by f2
range between 1 following and 2 following)
from t1 where f1 = f2
-- !query 32 schema
struct<f1:int,sum(f1) OVER (PARTITION BY f1, f2 ORDER BY f2 ASC NULLS FIRST RANGE BETWEEN 1 FOLLOWING AND 2 FOLLOWING):bigint>
-- !query 32 output
1	NULL
2	NULL


-- !query 33
SELECT rank() OVER (ORDER BY length('abc'))
-- !query 33 schema
struct<RANK() OVER (ORDER BY length(abc) ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW):int>
-- !query 33 output
1


-- !query 34
SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10
-- !query 34 schema
struct<>
-- !query 34 output
org.apache.spark.sql.AnalysisException
It is not allowed to use window functions inside WHERE and HAVING clauses;


-- !query 35
SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10
-- !query 35 schema
struct<>
-- !query 35 output
org.apache.spark.sql.AnalysisException

The query operator `Join` contains one or more unsupported
expression types Aggregate, Window or Generate.
Invalid expressions: [row_number() OVER (ORDER BY default.empsalary.`salary` ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)];


-- !query 36
SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1
-- !query 36 schema
struct<>
-- !query 36 output
org.apache.spark.sql.AnalysisException

The query operator `Aggregate` contains one or more unsupported
expression types Aggregate, Window or Generate.
Invalid expressions: [RANK() OVER (ORDER BY 1 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)];


-- !query 37
SELECT * FROM rank() OVER (ORDER BY random())
-- !query 37 schema
struct<>
-- !query 37 output
org.apache.spark.sql.catalyst.parser.ParseException

no viable alternative at input 'ORDER'(line 1, pos 27)

== SQL ==
SELECT * FROM rank() OVER (ORDER BY random())
---------------------------^^^


-- !query 38
SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10
-- !query 38 schema
struct<>
-- !query 38 output
org.apache.spark.sql.AnalysisException
It is not allowed to use window functions inside WHERE and HAVING clauses;


-- !query 39
SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random())
-- !query 39 schema
struct<>
-- !query 39 output
org.apache.spark.sql.AnalysisException
It is not allowed to use window functions inside WHERE and HAVING clauses;


-- !query 40
select rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1
-- !query 40 schema
struct<>
-- !query 40 output
org.apache.spark.sql.catalyst.parser.ParseException

no viable alternative at input 'ORDER'(line 1, pos 39)

== SQL ==
select rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1
---------------------------------------^^^


-- !query 41
SELECT range(1, 100) OVER () FROM empsalary
-- !query 41 schema
struct<>
-- !query 41 output
org.apache.spark.sql.AnalysisException
Undefined function: 'range'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 7


-- !query 42
SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1
-- !query 42 schema
struct<>
-- !query 42 output
org.apache.spark.sql.AnalysisException
cannot resolve 'ntile(0)' due to data type mismatch: Buckets expression must be positive, but got: 0; line 1 pos 7


-- !query 43
DROP TABLE empsalary
-- !query 43 schema
struct<>
-- !query 43 output



-- !query 44
DROP TABLE datetimes
-- !query 44 schema
struct<>
-- !query 44 output



-- !query 45
DROP TABLE t1
-- !query 45 schema
struct<>
-- !query 45 output

